{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.metrics.pairwise import linear_kernel, pairwise_distances\n",
    "\n",
    "from src.recommender import evaluate_recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_RECOMMENDATIONS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df = pd.read_csv(\"../datasets/movielens/ml-1m/ratings.csv\")\n",
    "movies_infos_df = pd.read_json(\"../datasets/movielens/omdb.csv\", lines=True)\n",
    "\n",
    "full_df = pd.merge(\n",
    "    ratings_df,\n",
    "    movies_infos_df,\n",
    "    left_index=True,\n",
    "    right_index=True\n",
    ")\n",
    "\n",
    "movies = ratings_df[\"movieId\"].unique().tolist()\n",
    "users = ratings_df[\"userId\"].unique().tolist()\n",
    "\n",
    "movie_index_to_id = movies_infos_df[\"id\"].to_dict()\n",
    "movie_id_to_index = {v: k for (k, v) in movie_index_to_id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df_filtered = full_df.loc[full_df[\"rating\"] >= 4]\n",
    "\n",
    "train_df, test_df = train_test_split(full_df_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "likes_per_user = \\\n",
    "    train_df.groupby(\"userId\")[\"movieId\"].apply(set).to_dict()\n",
    "\n",
    "target_recommendations_per_user = \\\n",
    "    test_df.groupby(\"userId\")[\"movieId\"].apply(set).to_dict()\n",
    "\n",
    "# e.g: `target_recommendations_per_user[2]` shows items we should predict for user 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_predict():\n",
    "    scores = []\n",
    "\n",
    "    for user_id in test_df[\"userId\"].unique():\n",
    "        target = target_recommendations_per_user[user_id]\n",
    "        predictions = predict(user_id)\n",
    "\n",
    "        score = evaluate_recommendations(predictions, target, k=N_RECOMMENDATIONS)\n",
    "        scores.append(score)\n",
    "\n",
    "    return np.mean(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(user_id):\n",
    "    recommended_movies = np.random.choice(movies, N_RECOMMENDATIONS)\n",
    "    \n",
    "    return recommended_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 138 ms, sys: 2.73 ms, total: 141 ms\n",
      "Wall time: 139 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.04288574288451783"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time evaluate_predict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Content Based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_vect = TfidfVectorizer()\n",
    "\n",
    "X = sparse.hstack([\n",
    "    genre_vect.fit_transform(movies_infos_df[\"Genre\"].fillna(\"\")),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_sim = linear_kernel(X, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(user_id):\n",
    "    movie_ids_liked_by_user = \\\n",
    "        train_df.loc[train_df[\"userId\"] == user_id][\"id\"].tolist()\n",
    "    \n",
    "    movie_indices_liked_by_user = [movie_id_to_index[movie_id]\n",
    "                                   for movie_id in movie_ids_liked_by_user]\n",
    "\n",
    "    recommended_movies = []\n",
    "    \n",
    "    for movie_index in movie_indices_liked_by_user:\n",
    "        sim_scores = list(enumerate(cosine_sim[movie_index]))\n",
    "        sim_scores_sorted = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        sim_scores_sorted = sim_scores_sorted[:(N_RECOMMENDATIONS // len(movie_indices_liked_by_user) + 1)]\n",
    "\n",
    "        recommended_movies_tmp = [movie_index_to_id[recommended_index]\n",
    "                                  for (recommended_index, score) in sim_scores_sorted]\n",
    "        \n",
    "        recommended_movies += recommended_movies_tmp\n",
    "        \n",
    "    return recommended_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04753234834849813"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_predict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collaborative Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = CountVectorizer(token_pattern=\"[0-9]+\")\n",
    "v.fit(train_df[\"movieId\"].astype(str));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_matrix(df, groupby_column, data_column):\n",
    "    grouped_df = df.groupby(groupby_column)\n",
    "    group_keys = list(grouped_df.groups.keys())\n",
    "    \n",
    "    data = grouped_df[data_column]\\\n",
    "            .apply(list)\\\n",
    "            .apply(lambda r: \" \".join(list(map(str, r))))\\\n",
    "            .tolist()\n",
    "    \n",
    "    return v.transform(data), group_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, train_users = make_matrix(train_df, groupby_column=\"userId\", data_column=\"movieId\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_sim = 1 - pairwise_distances(X_train, metric=\"cosine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(185, 185)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_sim.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(user_id, similarity_threshold=0.2):\n",
    "    user_index = train_users.index(user_id)\n",
    "    \n",
    "    sim_scores = list(enumerate(cosine_sim[user_index]))\n",
    "    sim_scores_sorted = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    recommended_movies = []\n",
    "    \n",
    "    candidates = [(user_index, score)\n",
    "                  for user_index, score in sim_scores_sorted\n",
    "                  if score > similarity_threshold]\n",
    "    \n",
    "    for similar_user_index, similarity_score in candidates:\n",
    "        similar_user_id = train_users[similar_user_index]\n",
    "        \n",
    "        if similar_user_id == user_id:\n",
    "            continue\n",
    "            \n",
    "        similar_user_likes = list(likes_per_user[similar_user_id])\n",
    "        \n",
    "        recommended_movies += similar_user_likes[:(N_RECOMMENDATIONS // len(candidates)) + 1]\n",
    "        \n",
    "    return recommended_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20323759379413636"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data",
   "language": "python",
   "name": "data"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
